
---
title: "probando fda"
author: "santiago eliges"
date: "2025-04-01"
output:
  html_document: default
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librer√≠as

```{r, warning=FALSE, message=FALSE}
library('fda')        # herramientas para tratar datos funcionales  
library('robustbase') # lmrob 
library(fda.usc)      # dataset + herramientas como fda (derivada, por ejemplo)
library(lattice)      # gr√°ficos
library(gdata)        # uppertriangle
library(splines2)
library(fastmatrix)
library(spacetime)
library(sp)
library(dplyr)
library(FRK)
library(matlib)
library(FactoMineR)
library(factoextra)
library(funcharts)
library(pROC)
```

```{r}

producto_interno_bases <- function(base1, base2 = NULL, a = 0, b = 1) {
  # Validaciones
  if (!is.matrix(base1)) stop("base1 debe ser una matriz")
  m <- nrow(base1)
  if (is.null(base2)) base2 <- base1
  if (nrow(base2) != m) stop("base1 y base2 deben tener el mismo n√∫mero de filas (puntos de la grilla)")
  
  # Paso de cuadratura trapezoidal
  h <- (b - a) / (m - 1)
  w <- rep(h, m)
  w[1] <- h / 2
  w[m] <- h / 2
  W <- diag(w)
  
  # Producto interno entre bases
  t(base1) %*% W %*% base2
}

```



Para hacer la simulaci√≥n, primero intento costruir a las funciones
aleatorias $X_i$ simulando a la matriz A de coordenadas en la base
$\phi$.

Primero, definimos a la base $\phi$ como la base de Bsplines en el
intervalo (0,10) con un knot en cada punto del intervalo (t√©rminamos
teniendo 13 funciones en la base).

**[DP: OK, gener√°s 200 curvas en (0,10) usando Bsplines. En el script
que dejo en la carpeta te propongo otra generaci√≥n, pero esta tambi√©n
est√° OK. Lo bueno es que todo en L2 es "llevable" al (0,1) as√≠ que, por
cuestiones de normalizaci√≥n (¬øponele?), mejor trabajamos ah√≠, ¬øte
parece?]**

```{r}
FPCA_empirica<- function(matriz_densa, Delta_t){
    n <- nrow(matriz_densa)
    # 6) FPCA emp√≠rica (densa)
    mu_hat     <- colMeans(matriz_densa)
    X_centered <- sweep(matriz_densa, 2, mu_hat, "-")
    C_hat      <- (t(X_centered) %*% X_centered) / n
    #C_hat <- (t(X_centered) %*% X_centered) * (Delta_t / n) #--> Siempre me genera duda estar comi√©ndome un delta, REVISARLO
    eig_C      <- eigen(C_hat, symmetric = TRUE)
    # a) extraer valores propios y ordenarlos
    eigvals    <- eig_C$values
    idx        <- order(eigvals, decreasing = TRUE)
    eigvals    <- eigvals[idx]
    # b) extraer autofunciones emp√≠ricas ordenadas
    phi_hat    <- eig_C$vectors[, idx, drop = FALSE]  # M √ó K_true
    Xi_hat     <- X_centered %*% phi_hat * Delta_t     # n √ó K_true
    return(list(eigvals, phi_hat, Xi_hat))
    }
```


```{r}
# 1. Simular -------------------------------------------------------------------
simulate_fpca_data <- function(n, M, beta_coef, gamma_coef, lambda_fun = function(k) k^(-2)) {
  t_grid   <- seq(0, 1, length.out = M)
  Delta_t  <- t_grid[2] - t_grid[1]
  K_true   <- length(beta_coef)
  lambda_k <- lambda_fun(1:K_true)
  
  # 1) Base verdadera (sinusoidal ortonormal en [0,1])
  Phi_true <- matrix(0, nrow = M, ncol = K_true)
  for (k in 1:K_true) {
    Phi_true[, k] <- sqrt(2) * sin((k - 0.5) * pi * t_grid)
  }
  
  #splinebasis <- create.bspline.basis(c(0,1),K_true)
  #Phi_true <- eval.basis(basisobj = splinebasis, evalarg = t_grid)
  
  # 2) Simular scores Xi_true ~ N(0, lambda_k)
  Xi_true <- matrix(rnorm(n * K_true, mean = 0, sd = sqrt(lambda_k)),
                    nrow = n, ncol = K_true, byrow = TRUE)
  
  # 3) Construir curvas "densas" X_mat = Xi_true %*% t(Phi_true)
  X_mat <- Xi_true %*% t(Phi_true)
  
  # 4) Predictor lineal + cuadr√°tico verdaderos
  Lin_part  <- Xi_true %*% beta_coef
  Quad_part <- rep(0, n)
  mat_idx   <- matrix(seq_len(K_true^2), nrow = K_true, ncol = K_true)
  combos    <- which(row(mat_idx) <= col(mat_idx), arr.ind = TRUE)
  for (m in seq_len(nrow(combos))) {
    j <- combos[m, 1]
    k <- combos[m, 2]
    coef_q <- gamma_coef[j, k] * (2 - ifelse(j == k, 1, 0))
    Quad_part <- Quad_part + coef_q * (Xi_true[, j] * Xi_true[, k])
  }
  eta_true <- Lin_part + Quad_part
  
  # 5) Simular Y_obs ~ Bernoulli(sigmoide(Œ∑_i))
  prob_true <- exp(eta_true) / (1 + exp(eta_true))
  Y_obs     <- rbinom(n, size = 1, prob = prob_true)
  
  # 6) FPCA emp√≠rica (densa)
  FPCA_empirica_densa <- FPCA_empirica(X_mat, Delta_t)
  eigvals <- FPCA_empirica_densa[[1]]
  phi_hat <- FPCA_empirica_densa[[2]]
  Xi_hat <- FPCA_empirica_densa[[3]]
  
  
  # 7) Reconstruir Œ≤_true(t) en la malla
  beta_true <- Phi_true[, 1:K_true] %*% beta_coef[1:K_true]
  
  # 8) Reconstruir Œ≥_true(s,t) en la malla
  gamma_true <- matrix(0, nrow = M, ncol = M)
  for (m in seq_len(nrow(combos))) {
    j      <- combos[m, 1]
    k      <- combos[m, 2]
    coef_t <- gamma_coef[j, k] * (2 - ifelse(j == k, 1, 0))
    gamma_true <- gamma_true +
      coef_t * (Phi_true[, j] %o% Phi_true[, k])
    if (j != k) {
      gamma_true <- gamma_true +
        coef_t * (Phi_true[, k] %o% Phi_true[, j])
    }
  }
  
  # 9) Devolver todo
  return(list(
    t_grid     = t_grid,
    Delta_t    = Delta_t,
    K_true     = K_true,
    Phi_true   = Phi_true,
    Xi_true    = Xi_true,
    X_mat      = X_mat,
    Y_obs      = Y_obs,
    eigvals    = eigvals, 
    phi_hat    = phi_hat,
    Xi_hat     = Xi_hat,
    beta_true  = beta_true,
    gamma_true = gamma_true
  ))
}
```


```{r}
library(glmnet)

fit_models_FPCA_regression <- function(X, Y, t_grid, var_threshold, alpha, crossValglmnet = FALSE,                        variableSelectionMethod = c("none", "AIC", "LRT")
) {
    variableSelectionMethod <- match.arg(variableSelectionMethod)
  
  n        <- nrow(X)
  Delta_t  <- t_grid[2] - t_grid[1]
  
  
  FPCA_empirica_densa <- FPCA_empirica(X, Delta_t)
  eigvals <- FPCA_empirica_densa[[1]]
  phi_hat <- FPCA_empirica_densa[[2]]
  Xi_hat <- FPCA_empirica_densa[[3]]
  
  cum_var <- cumsum(eigvals) / sum(eigvals)
  p        <- which(cum_var >= var_threshold)[1]

  mat_idx  <- matrix(seq_len(p^2), nrow = p, ncol = p)
  combos_p <- which(row(mat_idx) <= col(mat_idx), arr.ind = TRUE)
  
  
  Z_lin <- Xi_hat[, 1:p, drop = FALSE]
  
  Z_quad <- matrix(0, nrow = n, ncol = nrow(combos_p))
  for (m in seq_len(nrow(combos_p))) {
    j <- combos_p[m, 1]
    k <- combos_p[m, 2]
    Z_quad[, m] <- Xi_hat[, j] * Xi_hat[, k]
  }

  # Estandarizaci√≥n
  sd_lin       <- apply(Z_lin, 2, sd)
  Z_lin_scaled <- scale(Z_lin)
  
  Z_all        <- cbind(Z_lin, Z_quad)
  sds_all      <- apply(Z_all, 2, sd)
  Z_all_scaled <- scale(Z_all)

"  # Sin escalamiento
sd_lin       <- rep(1, ncol(Z_lin))
Z_lin_scaled <- Z_lin  # No se escala

Z_all        <- cbind(Z_lin, Z_quad)
sds_all      <- rep(1, ncol(Z_all))
Z_all_scaled <- Z_all  # No se escala"

  # Modelos LASSO
  if (crossValglmnet) {
      Z_lin_scaled <- as.matrix(Z_lin_scaled)
      Z_all_scaled <- as.matrix(Z_all_scaled)
      fit_lin <- cv.glmnet(Z_lin_scaled, Y, family = "binomial", alpha = alpha)
      fit_quad <- cv.glmnet(Z_all_scaled, Y, family = "binomial", alpha = alpha)
  }
  else{
    Z_lin_df <- as.data.frame(Z_lin_scaled)
    names(Z_lin_df) <- paste0("Z_lin", seq_len(ncol(Z_lin_df)))
    
    Z_all_df <- as.data.frame(Z_all_scaled)
    names(Z_all_df) <- paste0("Z_all", seq_len(ncol(Z_all_df)))
    
    fit_lin <- glm(Y ~ ., data = Z_lin_df, family = binomial)
    fit_quad <- glm(Y ~ ., data = Z_all_df, family = binomial)
  }
  if (!crossValglmnet && variableSelectionMethod != "none") {
    if (variableSelectionMethod == "AIC") {
      fit_lin <- step(fit_lin, direction = "forward", test = "AIC")
      fit_quad <- step(fit_quad, direction = "forward", test = "AIC")
    } else if (variableSelectionMethod == "LRT") {
      fit_lin <- step(fit_lin, direction = "forward", test = "LRT")
      fit_quad <- step(fit_quad, direction = "forward", test = "LRT")
    }
  }
 return(list(
    fit_lin      = fit_lin,
    fit_quad     = fit_quad,
    Z_lin_scaled = Z_lin_scaled,
    Z_all_scaled = Z_all_scaled,
    sd_lin       = sd_lin,
    sds_all      = sds_all,
    combos_p     = combos_p,
    p            = p,
    phi_hat      = phi_hat
  ))
}

```


```{r}
# 3. Funci√≥n: reconstruir Œ≤_hat y Œ≥_hat ----------------------------------------
reconstruct_functions <- function(phi_hat, p, fit_lin, fit_quad, sd_lin, sds_all, combos_p) {
  M <- nrow(phi_hat)
  
  b_scaled_lin   <- coef(fit_lin)[2:(p+1)]
  b_unscaled_lin <- b_scaled_lin / sd_lin
  beta_hat_lin   <- phi_hat[, 1:p] %*% b_unscaled_lin
  
  coef_scaled_quad <- coef(fit_quad)[-1]
  b_scaled_quad    <- coef_scaled_quad[1:p]
  a_scaled_quad    <- coef_scaled_quad[(p+1):length(coef_scaled_quad)]
  b_unscaled_quad  <- b_scaled_quad / sds_all[1:p]
  a_unscaled_quad  <- a_scaled_quad / sds_all[(p+1):length(sds_all)]
  beta_hat_quad    <- phi_hat[, 1:p] %*% b_unscaled_quad
  
  gamma_hat_quad <- matrix(0, nrow = M, ncol = M)
  for (m in seq_len(nrow(combos_p))) {
    j      <- combos_p[m, 1]
    k      <- combos_p[m, 2]
    coef_q <- a_unscaled_quad[m] / (2 - ifelse(j == k, 1, 0))
    gamma_hat_quad <- gamma_hat_quad +
      coef_q * (phi_hat[, j] %o% phi_hat[, k])
    if (j != k) {
      gamma_hat_quad <- gamma_hat_quad +
        coef_q * (phi_hat[, k] %o% phi_hat[, j])
    }
  }
  
  gamma_hat_lin <- matrix(0, nrow = M, ncol = M)
  
  return(list(
    beta_hat_lin   = beta_hat_lin,
    beta_hat_quad  = beta_hat_quad,
    gamma_hat_lin  = gamma_hat_lin,
    gamma_hat_quad = gamma_hat_quad
  ))
}

# 4. Graficar (con poda al 90% interior) y evaluar m√©tricas --------------------
# 4.1. Graficar Œ≤(t) en interior: podar 5% en cada extremo
plot_beta_interior <- function(t_grid, beta_true, beta_hat_lin, beta_hat_quad, title_suffix = "") {
  # Definir √≠ndices interiores
  interior_idx <- which(t_grid >= 0.05 & t_grid <= 0.95)
  t_int        <- t_grid[interior_idx]
  df_beta <- data.frame(
    t       = t_int,
    True    = beta_true[interior_idx],
    EstLin  = beta_hat_lin[interior_idx],
    EstQuad = beta_hat_quad[interior_idx]
  )
  df_beta_long <- reshape2::melt(df_beta, id.vars = "t",
                                 variable.name = "Modelo",
                                 value.name = "beta")
  
  p <- ggplot(df_beta_long, aes(x = t, y = beta, color = Modelo, linetype = Modelo)) +
    geom_line(size = 1) +
    scale_color_manual(values = c("black", "blue", "red")) +
    scale_linetype_manual(values = c("solid", "dashed", "twodash")) +
    labs(x = "t", y = expression(beta(t)),
         title = paste0("Œ≤(t) ‚Äì 90% interior ‚Äì ", title_suffix)) +
    theme_minimal() +
    theme(legend.position = "bottom",
          legend.title = element_blank(),
          plot.title = element_text(hjust = 0.5))
  
  print(p)
}

# 4.2. Graficar Œ≥(s,t) con contour en interior (podar bordes)
plot_gamma_contour_interior <- function(t_grid, gamma_true, gamma_hat_lin, gamma_hat_quad, title_suffix = "") {
  # Identificar √≠ndices interiores
  interior_idx <- which(t_grid >= 0.05 & t_grid <= 0.95)
  
  # Recortar las matrices gamma a interior_idx √ó interior_idx
  gt_int_ll <- gamma_true[interior_idx, interior_idx, drop = FALSE]
  gl_int_ll <- gamma_hat_lin[interior_idx, interior_idx, drop = FALSE]
  gq_int_ll <- gamma_hat_quad[interior_idx, interior_idx, drop = FALSE]
  t_int     <- t_grid[interior_idx]
  
  prep_gamma <- function(mat, tipo) {
    df <- reshape2::melt(mat)
    colnames(df) <- c("s_idx", "t_idx", "gamma")
    df$Tipo <- tipo
    df$s    <- t_int[df$s_idx]
    df$t    <- t_int[df$t_idx]
    return(df)
  }
  
  df_gamma_true <- prep_gamma(gt_int_ll, paste0("True ‚Äì ", title_suffix))
  df_gamma_lin  <- prep_gamma(gl_int_ll, paste0("Est. Lin. ‚Äì ", title_suffix))
  df_gamma_quad <- prep_gamma(gq_int_ll, paste0("Est. Quad. ‚Äì ", title_suffix))
  df_gamma_all  <- rbind(df_gamma_true, df_gamma_lin, df_gamma_quad)
  
  p <- ggplot(df_gamma_all, aes(x = t, y = s, z = gamma)) +
    geom_contour_filled(aes(fill = ..level..), bins = 20) +
    facet_wrap(~ Tipo, nrow = 1) +
    scale_fill_viridis_d(option = "plasma", name = expression(gamma(s, t))) +
    labs(x = "t", y = "s", title = paste0("Contour Œ≥(s,t) ‚Äì 90% interior ‚Äì ", title_suffix)) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5),
          strip.text = element_text(size = 10),
          axis.text  = element_text(size = 6),
          axis.title = element_text(size = 8))
  
  print(p)
}

plot_gamma_3d_interior <- function(t_grid, gamma_true, gamma_hat_quad, title_suffix = "") {
  # Encontrar √≠ndices interiores
  interior_idx <- which(t_grid >= 0.05 & t_grid <= 0.95)
  t_int        <- t_grid[interior_idx]
  
  # Recortar matrices
  gt_int <- gamma_true[interior_idx, interior_idx, drop = FALSE]
  gq_int <- gamma_hat_quad[interior_idx, interior_idx, drop = FALSE]
  
  theta   <- 30
  phi_ang <- 30
  col_t   <- "lightblue"
  col_q   <- "lightcoral"
  
  # Calcular zmin y zmax combinados para las dos submatrices
  zmin <- min(c(gt_int, gq_int), na.rm = TRUE)
  zmax <- max(c(gt_int, gq_int), na.rm = TRUE)
  if (abs(zmax - zmin) < 1e-8) {
    zmin <- zmin - 1e-6
    zmax <- zmax + 1e-6
  }
  
  op <- par(mfrow = c(1, 2), mar = c(3, 3, 3, 1))
  
  persp(x      = t_int,
        y      = t_int,
        z      = gt_int,
        theta  = theta,
        phi    = phi_ang,
        expand = 1,
        col    = col_t,
        zlim   = c(zmin, zmax),
        ticktype = "detailed",
        xlab   = "t",
        ylab   = "s",
        zlab   = expression(gamma(s, t)),
        main   = paste0("Œ≥_true ‚Äì 90% interior ‚Äì ", title_suffix),
        cex.main = 1.1, cex.lab = 0.9, cex.axis = 0.7)
  
  persp(x      = t_int,
        y      = t_int,
        z      = gq_int,
        theta  = theta,
        phi    = phi_ang,
        expand = 1,
        col    = col_q,
        zlim   = c(zmin, zmax),
        ticktype = "detailed",
        xlab   = "t",
        ylab   = "s",
        zlab   = expression(hat(gamma)(s, t)),
        main   = paste0("Œ≥_hat_quad ‚Äì 90% interior ‚Äì ", title_suffix),
        cex.main = 1.1, cex.lab = 0.9, cex.axis = 0.7)
  
  par(op)
}


# 4.4. Matriz de confusi√≥n y CCR
calculate_confusion <- function(y_true, y_pred) {
  TP  <- sum(y_true == 1 & y_pred == 1)
  TN  <- sum(y_true == 0 & y_pred == 0)
  FP  <- sum(y_true == 0 & y_pred == 1)
  FN  <- sum(y_true == 1 & y_pred == 0)
  CCR <- (TP + TN) / length(y_true)
  return(list(TN = TN, FP = FP, FN = FN, TP = TP, CCR = CCR))
}

```


```{r}

# 4.5. M√©tricas: matriz de confusi√≥n, CCR, ROC y AUC
compute_metrics <- function(fit_lin, fit_quad, Y_val, Z_lin_scaled, Z_all_scaled,
                            crossValglmnet, plot_rocs = TRUE) {
  if (crossValglmnet) {
    prob_lin   <- predict(fit_lin, newx = Z_lin_scaled, type = "response", s = "lambda.min")
    prob_quad  <- predict(fit_quad, newx = Z_all_scaled, type = "response", s = "lambda.min")
  } else {
    Z_lin_val_df <- as.data.frame(Z_lin_scaled)
    names(Z_lin_val_df) <- paste0("Z_lin", seq_len(ncol(Z_lin_val_df)))
    
    Z_all_val_df <- as.data.frame(Z_all_scaled)
    names(Z_all_val_df) <- paste0("Z_all", seq_len(ncol(Z_all_val_df)))
    
    prob_lin <- predict(fit_lin, newdata = Z_lin_val_df, type = "response")
    prob_quad <- predict(fit_quad, newdata = Z_all_val_df, type = "response")
  }
  
  pred_lin  <- ifelse(prob_lin > 0.5, 1, 0)
  pred_quad <- ifelse(prob_quad > 0.5, 1, 0)
  
  res_lin   <- calculate_confusion(Y_val, pred_lin)
  res_quad  <- calculate_confusion(Y_val, pred_quad)
  
  roc_lin   <- roc(response = Y_val, predictor = as.vector(prob_lin))
  roc_quad  <- roc(response = Y_val, predictor = as.vector(prob_quad))
  
  auc_lin   <- auc(roc_lin)
  auc_quad  <- auc(roc_quad)
  
  if (plot_rocs) {
    plot(roc_lin,  col = "blue", lwd = 2,
         main = "Curva ROC Validaci√≥n",
         legacy.axes = TRUE)
    lines(roc_quad, col = "red", lwd = 2)
    abline(a = 0, b = 1, lty = 3, col = "gray40")
    legend("bottomright",
           legend = c(
             sprintf("Lineal  (AUC = %.3f)", auc_lin),
             sprintf("Cuadr√°tico (AUC = %.3f)", auc_quad)
           ),
           col  = c("blue", "red"),
           lwd  = 2,
           bty  = "n")
  }
  
  return(list(
    confusion_lin   = res_lin,
    confusion_quad  = res_quad,
    auc_lin         = auc_lin,
    auc_quad        = auc_quad,
    roc_lin         = roc_lin,
    roc_quad        = roc_quad
  ))
}
```

```{r}

ajustar_y_graficar_modelos_FPCA_regression <- function(X,
                                                       Y,
                                                       t_grid,
                                                       beta_true,
                                                       gamma_true,
                                       var_threshold = 0.70, 
                                       alpha = 0,
                                       crossValglmnet = FALSE,
                                       variableSelection = "LRT",
                                       scenario_name = "Escenario",
                                       plot_results = TRUE) {
  # 5.3. Ajustar modelos lineal y cuadr√°tico
  fits <- fit_models_FPCA_regression(
    X                 = X,
    Y                 = Y,
    t_grid            = t_grid,
    var_threshold     = var_threshold,
    alpha             = alpha,
    crossValglmnet    = crossValglmnet,
    variableSelection = variableSelection
  )
  
  fit_lin      <- fits$fit_lin
  fit_quad     <- fits$fit_quad
  Z_lin_scaled <- fits$Z_lin_scaled
  Z_all_scaled <- fits$Z_all_scaled
  sd_lin       <- fits$sd_lin
  sds_all      <- fits$sds_all
  combos_p     <- fits$combos_p
  p            <- fits$p
  phi_hat      <- fits$phi_hat
  
  # 5.4. Reconstruir funciones estimadas
  rec <- reconstruct_functions(
    phi_hat     = phi_hat,
    p           = p,
    fit_lin     = fit_lin,
    fit_quad    = fit_quad,
    sd_lin      = sd_lin,
    sds_all     = sds_all,
    combos_p    = combos_p
  )
  
  beta_hat_lin   <- rec$beta_hat_lin
  beta_hat_quad  <- rec$beta_hat_quad
  gamma_hat_lin  <- rec$gamma_hat_lin
  gamma_hat_quad <- rec$gamma_hat_quad

  # 5.5 y 5.6. Gr√°ficos (si corresponde)
  if (plot_results) {
    plot_beta_interior(
      t_grid        = t_grid,
      beta_true     = beta_true,
      beta_hat_lin  = beta_hat_lin,
      beta_hat_quad = beta_hat_quad,
      title_suffix  = paste0(scenario_name, " (p=", p, ")")
    )

    plot_gamma_contour_interior(
      t_grid         = t_grid,
      gamma_true     = gamma_true,
      gamma_hat_lin  = gamma_hat_lin,
      gamma_hat_quad = gamma_hat_quad,
      title_suffix   = paste0(scenario_name, " (p=", p, ")")
    )

    plot_gamma_3d_interior(
      t_grid         = t_grid,
      gamma_true     = gamma_true,
      gamma_hat_quad = gamma_hat_quad,
      title_suffix   = paste0(scenario_name, " (p=", p, ")")
    )

    par(mfrow = c(1, 1))  # Reset layout
  }

  # Devolver resultados incluyendo hiperpar√°metros usados
  return(list(
    fit_lin           = fit_lin,
    fit_quad          = fit_quad,
    beta_hat_lin      = beta_hat_lin,
    beta_hat_quad     = beta_hat_quad,
    gamma_hat_lin     = gamma_hat_lin,
    gamma_hat_quad    = gamma_hat_quad,
    phi_hat           = phi_hat,
    p                 = p,
    # Hiperpar√°metros
    var_threshold     = var_threshold,
    alpha             = alpha,
    crossValglmnet    = crossValglmnet,
    variableSelection = variableSelection
  ))
}

```

```{r}


evaluar_modelo_funcional_FPCA_regression <- function(modelo, X, Y, t_grid,plot = FALSE) {
  Delta_t = t_grid[2] - t_grid[1]
  FPCA_empirica_densa <- FPCA_empirica(X, Delta_t)
  eigvals <- FPCA_empirica_densa[[1]]
  phi_hat <- FPCA_empirica_densa[[2]]
  Xi_hat <- FPCA_empirica_densa[[3]]
  
"  cum_var <- cumsum(eigvals) / sum(eigvals)
  p        <- which(cum_var >= modelo$var_threshold)[1]"
  p <- modelo$p
  mat_idx  <- matrix(seq_len(p^2), nrow = p, ncol = p)
  combos_p <- which(row(mat_idx) <= col(mat_idx), arr.ind = TRUE)
  
  
  Z_lin <- Xi_hat[,1:p]
  
  Z_quad <- matrix(0, nrow = nrow(X), ncol = nrow(combos_p))
  for (m in seq_len(nrow(combos_p))) {
    j <- combos_p[m, 1]
    k <- combos_p[m, 2]
    Z_quad[, m] <- Xi_hat[, j] * Xi_hat[, k]
  }
    # Estandarizaci√≥n
  sd_lin       <- apply(Z_lin, 2, sd)
  Z_lin_scaled <- scale(Z_lin)
  
  Z_all        <- cbind(Z_lin, Z_quad)
  sds_all      <- apply(Z_all, 2, sd)
  Z_all_scaled <- scale(Z_all)

  res <- compute_metrics(
    fit_lin        = modelo$fit_lin,
    fit_quad       = modelo$fit_quad,
    Y_val          = Y,
    Z_lin_scaled   = Z_lin_scaled,
    Z_all_scaled   = Z_all_scaled,
    crossValglmnet = modelo$crossValglmnet,
    plot_rocs      = plot
  )

  return(res)
}

```

```{r}



simular_datos_funcionales_binarios <- function(n = 200, M = 101, K_true = 10,
                                               var_threshold = 0.95,
                                               lambda_fun = function(k) k^-2,
                                               beta_coef_custom = NULL,
                                               gamma_coef_custom = NULL) {
  
  # 1) Par√°metros y base
  t_grid <- seq(0, 1, length.out = M)
  Delta_t <- t_grid[2] - t_grid[1]
  
  #Bs_basis <- create.bspline.basis(c(0, 1), K_true)
  #Phi_true <- eval.basis(t_grid, Bs_basis)
  
  Phi_true <- matrix(0, nrow = M, ncol = K_true)
  for (k in 1:K_true) {
    Phi_true[, k] <- sqrt(2) * sin((k - 0.5) * pi * t_grid)
  }
  
  
  
  lambda_k <- lambda_fun(1:K_true)
  means <- runif(K_true, min = -0.001, max = 0.001)
  stdvs <- lambda_k
  
  # 2) Simular coeficientes A
  A_true <- matrix(rnorm(n * K_true, mean = rep(means, each = n), sd = rep(stdvs, each = n)),
                   nrow = n, ncol = K_true)
  
  # 3) Producto interno Psi (matriz de Gram de la base)
  "  Psi_true <- inprod(Bs_basis,
                     Bs_basis)"
  Psi_true <- producto_interno_bases(Phi_true)
  # 4) Escalar A y reconstruir X
  A_means <- colMeans(A_true)
  A_sds <- apply(A_true, 2, sd)
  A_true_scaled <- scale(A_true, center = A_means, scale = A_sds)
  X_true <- A_true_scaled %*% t(Phi_true)
  
  # 5) Construir B_true_scaled para t√©rminos cuadr√°ticos
  B_true_scaled <- matrix(NA, nrow = n, ncol = K_true * (K_true + 1) / 2)
  contador <- 1
  for (j in 1:K_true) {
    for (k in 1:j) {
      B_true_scaled[, contador] <- (2 - (j == k)) * A_true_scaled[, j] * A_true_scaled[, k]
      contador <- contador + 1
    }
  }
  
  # 6) Matriz Omega_true (producto tensorial cuadr√°tico)
  mat_idx <- matrix(1:(K_true * K_true), nrow = K_true, ncol = K_true)
  combos <- which(row(mat_idx) >= col(mat_idx), arr.ind = TRUE)
  combos <- combos[order(combos[, 1], combos[, 2]), ]
  
  Omega_true <- matrix(0, nrow = ncol(B_true_scaled), ncol = ncol(B_true_scaled))
  for (m in 1:nrow(Omega_true)) {
    for (√± in 1:ncol(Omega_true)) {
      i1 <- combos[m, 1]
      i2 <- combos[m, 2]
      j1 <- combos[√±, 1]
      j2 <- combos[√±, 2]
      Omega_true[m, √±] <- Psi_true[i1, j1] * Psi_true[i2, j2]
    }
  }
  
  # 7) Predictor lineal + cuadr√°tico
  gamma_lower_by_row <- gamma_coef_A[lower.tri(gamma_coef_A, diag = TRUE)]
  Lin_part <- A_true_scaled %*% Psi_true %*% beta_coef_A
  Quad_part <- B_true_scaled %*% Omega_true %*% gamma_lower_by_row
  eta_true <- Lin_part + Quad_part
  
  # 8) Simulaci√≥n de respuestas binarias
  prob_true <- exp(eta_true) / (1 + exp(eta_true))
  Y_obs <- rbinom(n, size = 1, prob = prob_true)
  
  # 9) beta(t)
  beta_true <- Phi_true %*% beta_coef_custom
  
  # 10) gamma(s,t)
  gamma_true <- matrix(0, nrow = M, ncol = M)
  for (m in seq_len(nrow(combos))) {
    j <- combos[m, 1]
    k <- combos[m, 2]
    coef_t <- gamma_coef_custom[j, k] * (2 - ifelse(j == k, 1, 0))
    gamma_true <- gamma_true +
      coef_t * (Phi_true[, j] %o% Phi_true[, k])
    if (j != k) {
      gamma_true <- gamma_true +
        coef_t * (Phi_true[, k] %o% Phi_true[, j])
    }
  }
  
  return(list(
    t_grid = t_grid,
    Delta_t = Delta_t,
    K_true = K_true,
    Phi_true = Phi_true,
    X_true = X_true,
    Y_obs = Y_obs,
    beta_true = beta_true,
    gamma_true = gamma_true
  ))
}
```

```{r}

# 6. Algunos escenarios --------------------------------------------------------
#   ‚Ä¢ A: mezcla de t√©rminos cuadr√°ticos e interacci√≥n en (1,1),(1,3),(3,5)
#   ‚Ä¢ B: solo parte lineal (Œ≤ ‚â† 0, Œ≥ = 0)
#   ‚Ä¢ C: solo parte cuadr√°tica en (2,2) y (4,4)
# 6.1. Escenario A: "Lineal y cuadr√°tico"
"
K_true <- 16

beta_coef_A <- numeric(K_true)
beta_coef_A[1:5] <- c(0.1, 0.3,0.33,-1,4)

gamma_coef_A <- matrix(0, nrow = K_true, ncol = K_true)
gamma_coef_A[1, 1] <- 1.5
gamma_coef_A[3, 3] <- -0.7
gamma_coef_A[3, 2] <- 0.3"
K_true <- 10
beta_coef_A <- numeric(10)
beta_coef_A[1] <- 2
beta_coef_A[2] <- 7.0
beta_coef_A[9] <- 6.0
gamma_coef_A <- matrix(0, nrow = 10, ncol = 10)
gamma_coef_A[1, 1] <- 6.5
gamma_coef_A[1, 3] <- -2.0
gamma_coef_A[3, 5] <- 4.0

sim <- simular_datos_funcionales_binarios(gamma_coef_custom = gamma_coef_A,
                                          beta_coef_custom = beta_coef_A,
                                          K_true = K_true,
                                          n = 3000, M=300)

modelo <- ajustar_y_graficar_modelos_FPCA_regression(
  X = sim$X_true,
  Y = sim$Y_obs,
  beta_true = sim$beta_true,
  t_grid =  sim$t_grid,
  gamma_true = sim$gamma_true,
  plot_results  = TRUE )

evaluar_modelo_funcional_FPCA_regression(modelo = modelo, X = sim$X_true, Y = sim$Y_obs, t_grid = sim$t_grid, plot = TRUE)

```


```{r}
grid_search_cv_FPCA_regression <- function(X, Y, t_grid, beta_true, gamma_true,
                           var_threshold_vals,
                           variableSelection_vals, crossVal_vals, alpha_vals,
                           nfolds = 2, seed = 123) {

  set.seed(seed)
  n <- nrow(X)

  # Dividir en conjunto de entrenamiento y conjunto de test final (20%)
  idx_total <- 1:n
  idx_test_final <- sample(idx_total, size = round(0.2 * n))
  idx_train_total <- setdiff(idx_total, idx_test_final)

  X_train_total <- X[idx_train_total, ]
  Y_train_total <- Y[idx_train_total]
  X_test_final <- X[idx_test_final, ]
  Y_test_final <- Y[idx_test_final]

  # Crear folds de cross-validation sobre el conjunto de entrenamiento
  folds <- sample(rep(1:nfolds, length.out = length(idx_train_total)))

  resultados_grid <- list()
  contador <- 1

  for (var_threshold in var_threshold_vals) {
    for (cv in crossVal_vals) {
      for (vs in variableSelection_vals) {
        for (a in alpha_vals) {
          if ((cv && vs != "none") || (!cv && a != 0)) next

          cat(sprintf("Par√°metros #%d: vt=%.2f, CV=%s, VS=%s, alpha=%.2f\n",
                      contador, var_threshold, cv, vs, a))

          metricas_fold <- list()

          for (k in 1:nfolds) {
            idx_valid <- which(folds == k)
            idx_train <- setdiff(1:length(idx_train_total), idx_valid)

            X_train <- X_train_total[idx_train, ]
            Y_train <- Y_train_total[idx_train]
            X_valid <- X_train_total[idx_valid, ]
            Y_valid <- Y_train_total[idx_valid]

            res <- tryCatch({
              ajustar_y_graficar_modelos_FPCA_regression(
                t_grid = t_grid,
                X = X_train,
                Y = Y_train,
                beta_true = beta_true,
                gamma_true = gamma_true,
                var_threshold = var_threshold,
                crossValglmnet = cv,
                variableSelection = vs,
                alpha = a,
                plot_results = FALSE
              )
            }, error = function(e) {
              message(sprintf("Error en fold %d: %s", k, e$message))
              return(NULL)
            })

            if (is.null(res)) {
              next
            }

            metrica <- evaluar_modelo_funcional_FPCA_regression(modelo = res,
                                                  X = X_valid,
                                                  Y = Y_valid,
                                                  t_grid = t_grid,
                                                  plot = FALSE)

            metricas_fold[[k]] <- metrica  

          }

          resultados_grid[[contador]] <- list(
            var_threshold = var_threshold,
            crossValglmnet = cv,
            variableSelection = vs,
            alpha = a,
            metricas = metricas_fold
          )
          contador <- contador + 1
        }
      }
    }
  }

  auroc_promedios <- numeric(length(resultados_grid))

  for (i in seq_along(resultados_grid)) {
    metricas_folds <- resultados_grid[[i]]$metricas
    metricas_folds <- Filter(Negate(is.null), metricas_folds)
    aurocs <- sapply(metricas_folds, function(m) m$auc_quad)
    auroc_promedios[i] <- mean(aurocs)
  }

  mejor_indice <- which.max(auroc_promedios)
  mejor_modelo <- resultados_grid[[mejor_indice]]

  cat("Mejor AUROC promedio:", auroc_promedios[mejor_indice], "\n")
  cat("Par√°metros del mejor modelo:\n")
  print(mejor_modelo[c("var_threshold", "crossValglmnet", "variableSelection", "alpha")])

  cat("\nGraficando mejor modelo sobre conjunto de entrenamiento completo...\n")
  res_mejor_modelo <- ajustar_y_graficar_modelos_FPCA_regression(
    t_grid = t_grid,
    X = X_train_total,
    Y = Y_train_total,
    beta_true = beta_true,
    gamma_true = gamma_true,
    var_threshold = mejor_modelo$var_threshold,
    crossValglmnet = mejor_modelo$crossValglmnet,
    variableSelection = mejor_modelo$variableSelection,
    alpha = mejor_modelo$alpha,
    plot_results = TRUE
  )

  cat("\nEvaluando en conjunto de test final...\n")
  evaluar_modelo_funcional_FPCA_regression(modelo = res_mejor_modelo,
                                           X = X_test_final,
                                           Y = Y_test_final,
                                           t_grid = t_grid,
                                           plot = TRUE)

  return(list(resultados_grid = resultados_grid,
              mejor_modelo = mejor_modelo,
              X_test_final = X_test_final,
              Y_test_final = Y_test_final))
}

```


```{r}
sim <- simular_datos_funcionales_binarios(gamma_coef_custom = gamma_coef_A,
                                          beta_coef_custom = beta_coef_A,
                                          K_true = K_true,
                                          n = 3000, M=201)

var_threshold_vals = c(0.75,0.8, 0.85, 0.9, 0.95, 0.99)
variableSelection_vals = c("none", "LRT", "AIC")
crossVal_vals = c(FALSE, TRUE)
alpha_vals = c(0,0.5,1)

grid <- grid_search_cv_FPCA_regression(X = sim$X_true, Y = sim$Y_obs, t_grid = sim$t_grid, beta_true =  sim$beta_true, gamma_true = sim$gamma_true, var_threshold_vals =  var_threshold_vals, variableSelection_vals = variableSelection_vals, crossVal_vals = crossVal_vals, alpha_vals = alpha_vals)
```

```{r}
K_true <- 10
beta_coef_A <- numeric(10)
beta_coef_A[1] <- 2
beta_coef_A[2] <- -2.5
gamma_coef_A <- matrix(0, nrow = 10, ncol = 10)
gamma_coef_A[1, 1] <- 6.5
gamma_coef_A[1, 3] <- -5.0
gamma_coef_A[2, 3] <- -4.3
gamma_coef_A[2, 2] <- -7.0
gamma_coef_A[3, 5] <- 10.0

sim <- simular_datos_funcionales_binarios(gamma_coef_custom = gamma_coef_A,
                                          beta_coef_custom = beta_coef_A,
                                          K_true = K_true,
                                          n = 3000, M=201)

grid <- grid_search_cv_FPCA_regression(X = sim$X_true, Y = sim$Y_obs, t_grid = sim$t_grid, beta_true =  sim$beta_true, gamma_true = sim$gamma_true, var_threshold_vals =  var_threshold_vals, variableSelection_vals = variableSelection_vals, crossVal_vals = crossVal_vals, alpha_vals = alpha_vals)
```
```{r}
library(caret)    # Para K-Fold y entrenamiento
library(dplyr)    # Para manipulaci√≥n de datos
library(ggplot2)  # 

# Crear las columnas al cuadrado
X <- as.data.frame(sim$X_true)
X_sq <- X^2

# Renombrar las columnas cuadr√°ticas para diferenciarlas
colnames(X_sq) <- paste0(colnames(X), "_sq")

# Combinar con los datos originales
data_sim <- cbind(X, X_sq, Y = factor(sim$Y_obs))

# Convertir la respuesta en factores "yes" / "no" (requerido por caret)
data_sim$Y <- factor(ifelse(data_sim$Y == 1, "yes", "no"), levels = c("no", "yes"))


#separo conjunto de held-out
set.seed(123)
idx <- sample(1:nrow(data_sim), 0.8 * nrow(data_sim))
data_train <- data_sim[idx, ]
data_test  <- data_sim[-idx, ]

# Definir control de entrenamiento con 5-fold CV
control <- trainControl(
  method = "cv",
  number = 4,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = TRUE,
  sampling = NULL,
  index = createFolds(data_train$Y, k = 4, returnTrain = TRUE) # üëà estratificaci√≥n manual
)


#data_sim = cbind(X = as.data.frame(sim$X_true), Y = factor(sim$Y_obs))

# Ajustar modelo de regresi√≥n log√≠stica
modelo_log <- train(
  Y ~ ., 
  data = data_train,
  method = "glm",
  family = binomial,
  trControl = control,
  metric = "ROC"
)

# Predecir en test
pred_test <- predict(modelo_log, newdata = data_test, type = "prob")
auc_heldout <- auc(roc(response = data_test$Y, predictor = pred_test$yes))
cat("AUC-ROC en held-out:", round(auc_heldout, 4), "\n")

# Calcular AUC-ROC promedio por fold
library(pROC)
auc_por_fold <- preds %>%
  group_by(Resample) %>%
  summarise(AUC = as.numeric(auc(roc(response = obs, predictor = yes))))

auc_promedio <- mean(auc_por_fold$AUC)
print(auc_por_fold)
cat("AUC-ROC promedio:", round(auc_promedio, 4), "\n")


```
```{r}
sum(sim$Y_obs)/length(sim$Y_obs)
```



